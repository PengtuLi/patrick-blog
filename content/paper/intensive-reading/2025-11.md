- `KV cache, serve, agent` **Tokencake: A KV-Cache-centric Serving Frameworkfor LLM-based Multi-Agent Applications**. Zhuohang Bian et.al. **arxiv'2510**, [link](https://arxiv.org/pdf/2510.18586)
  - PKU
  - research problem:
    - multi-agent app serving
      - kv cacge闲置导致bs开不大。ayo,仅仅pipeline去重叠llm和tool call,但是kvcache stalled,没有被利用,这里的kv cache指掉func call的llm的kv cache,多agent这个问题更严重
      - kv cache关键路径被逐出的问题，FCFS会导致重要kv cache被逐出，导致重计算
        - 本质上就是多个分支下，关键分支（执行时间长）由于图的结构被抢占
  - key insight:
    - 可以利用stalled的agent的那部分显存去做别的请求的计算
    - 关键路径上的agent应该预先保留一部分一资源
  - key idea:
    - managing KV Cache resources across both time and space dimensions. 去提升显存利用率。
  - core method:
    - time scheduler
      - 事件驱动的offload,当tool调用时offload,预测tool时间prefetch
      - offline冷启动预测时间 + online动态修正预测时间
      - 根据收益函数判断是否offload,有请求可以在tool的这段时间内完成
      - 优化offload开销，offload大量page block开销大，采用GPU块缓存
      - 解决prefetch时有可用的gpu显存： 根据预测时间逐步回收显存
    - space scheduler
      - 显存分成两部分，一部分单独留给重要的agent
        - 重要agent是动态选择的,根据静态（DAG）+动态（prefer short req）确定重要性
        - 根据agent历史数据和重要性确定显存分配比例
  - TLDR:
    - 定义的非常好，agent-tool + agent-agent interaction
    - 场景非常不错，multi-agent coding, deep research
    - 测量了不同tool的latency distribution,有参考意义
    - 关于请求pipeline的过程没有说明，可能是侧重点的问题把

典型工作：
ayo,parrot,autellix
KV-COMM,KV-FLOW,Token-cake,Continuum
droidspeak,

重要的问题：

- 动态变化的DAG图没有考虑？对于kvcache复用的影响
- 长序列kv-cache的优化，大量的offload,agent下的pd分离？
- kv cache复用，maybe多lora maybe mooncake like? agent特性相关
- droidspeak NSDI26,复用到agent场景，同一大小模型同一系列不同微调版本可以复用
